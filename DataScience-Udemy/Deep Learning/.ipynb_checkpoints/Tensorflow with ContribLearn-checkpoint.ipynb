{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow with ContribLearn\n",
    "\n",
    "As we saw previously how to build a full Multi-Layer Perceptron model with full Sessions in Tensorflow. Unfortunately this was an extremely involved process. However developers have created ContribLearn (previously known as TKFlow or SciKit-Flow) which provides a SciKit Learn like interface for Tensorflow!\n",
    "\n",
    "It is much easier to use, but you sacrifice some level of customization of your model. Let's go ahead and explore it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhaval\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "C:\\Users\\Dhaval\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dhaval\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From C:\\Users\\Dhaval\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:378: multi_class_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.contrib.estimator.*_head.\n",
      "WARNING:tensorflow:From C:\\Users\\Dhaval\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:1165: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
      "WARNING:tensorflow:From C:\\Users\\Dhaval\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:427: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000017DC63E0940>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './output'}\n",
      "WARNING:tensorflow:From <ipython-input-1-c9271ad0c842>:24: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-1-c9271ad0c842>:24: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From C:\\Users\\Dhaval\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:494: SKCompat.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to the Estimator interface.\n",
      "WARNING:tensorflow:From C:\\Users\\Dhaval\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:142: setup_train_data_feeder (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From C:\\Users\\Dhaval\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:96: extract_dask_data (from tensorflow.contrib.learn.python.learn.learn_io.dask_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please feed input to tf.data to support dask.\n",
      "WARNING:tensorflow:From C:\\Users\\Dhaval\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:98: extract_dask_labels (from tensorflow.contrib.learn.python.learn.learn_io.dask_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please feed input to tf.data to support dask.\n",
      "WARNING:tensorflow:From C:\\Users\\Dhaval\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:100: extract_pandas_data (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please access pandas data directly.\n",
      "WARNING:tensorflow:From C:\\Users\\Dhaval\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:102: extract_pandas_labels (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please access pandas data directly.\n",
      "WARNING:tensorflow:From C:\\Users\\Dhaval\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:159: DataFeeder.__init__ (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From C:\\Users\\Dhaval\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:340: check_array (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please convert numpy dtypes explicitly.\n",
      "WARNING:tensorflow:From C:\\Users\\Dhaval\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./output\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.4232154, step = 1\n",
      "INFO:tensorflow:global_step/sec: 677.518\n",
      "INFO:tensorflow:loss = 0.13561918, step = 101 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 1113.89\n",
      "INFO:tensorflow:loss = 0.081079386, step = 201 (0.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 1017.19\n",
      "INFO:tensorflow:loss = 0.070498526, step = 301 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1017.33\n",
      "INFO:tensorflow:loss = 0.06583487, step = 401 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 1079.2\n",
      "INFO:tensorflow:loss = 0.0621539, step = 501 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 1023.27\n",
      "INFO:tensorflow:loss = 0.060167123, step = 601 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1074.39\n",
      "INFO:tensorflow:loss = 0.058659095, step = 701 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 984.317\n",
      "INFO:tensorflow:loss = 0.057550207, step = 801 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 1031.06\n",
      "INFO:tensorflow:loss = 0.05659398, step = 901 (0.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 1058.49\n",
      "INFO:tensorflow:loss = 0.05570993, step = 1001 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1045.36\n",
      "INFO:tensorflow:loss = 0.054957114, step = 1101 (0.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 1116.6\n",
      "INFO:tensorflow:loss = 0.05431571, step = 1201 (0.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 1087.41\n",
      "INFO:tensorflow:loss = 0.053659856, step = 1301 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 1054.56\n",
      "INFO:tensorflow:loss = 0.053027067, step = 1401 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1074.03\n",
      "INFO:tensorflow:loss = 0.052516818, step = 1501 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 1107.71\n",
      "INFO:tensorflow:loss = 0.052012842, step = 1601 (0.090 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1090.36\n",
      "INFO:tensorflow:loss = 0.051449556, step = 1701 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 1106.47\n",
      "INFO:tensorflow:loss = 0.051011357, step = 1801 (0.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 1070.09\n",
      "INFO:tensorflow:loss = 0.050605394, step = 1901 (0.093 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./output\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.05010333.\n",
      "WARNING:tensorflow:From <ipython-input-1-c9271ad0c842>:27: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-1-c9271ad0c842>:27: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-15-23:52:07\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./output\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-15-23:52:07\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.9777778, global_step = 2000, loss = 0.041057628\n",
      "Accuracy: 0.977778\n",
      "WARNING:tensorflow:From C:\\Users\\Dhaval\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:497: calling DNNClassifier.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_classes, or set `outputs` argument.\n",
      "WARNING:tensorflow:From C:\\Users\\Dhaval\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:463: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./output\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      0.95      0.97        19\n",
      "          2       0.93      1.00      0.96        13\n",
      "\n",
      "avg / total       0.98      0.98      0.98        45\n",
      "\n",
      "\n",
      "\n",
      "[[13  0  0]\n",
      " [ 0 18  1]\n",
      " [ 0  0 13]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    " \n",
    "# Data sets\n",
    "iris = load_iris()\n",
    "X =np.float32(iris['data']) \n",
    "y = iris['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)\n",
    " \n",
    "# Specify that all features have real-value data\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]\n",
    " \n",
    "# Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                            hidden_units=[10, 20, 10],\n",
    "                                            n_classes=3,\n",
    "                                            model_dir=\"./output\")\n",
    " \n",
    "# Fit model.\n",
    "classifier.fit(X_train, y_train, steps=2000)\n",
    " \n",
    "# Evaluate accuracy.\n",
    "accuracy_score = classifier.evaluate(X_test, y_test)[\"accuracy\"]\n",
    "print('Accuracy: {0:f}'.format(accuracy_score))\n",
    " \n",
    "#Evaluate with classification report and confusion matrix\n",
    "iris_predictions = list(classifier.predict(X_test))\n",
    "print(classification_report(y_test,  iris_predictions))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,  iris_predictions))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data\n",
    "\n",
    "We will the iris data set.\n",
    "\n",
    "Let's get the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = iris['data']\n",
    "X = np.float32(iris['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrib.learn\n",
    "\n",
    "Let's show you how to use the simpler contrib.learn interface!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.learn as learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several high level abstraction calls to models in learn, you can explore them with Tab, but we will use DNNClassifier, which stands for Deep Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000017DC7BC58D0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './output'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./output\\model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 4001 into ./output\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.029623033, step = 4001\n",
      "INFO:tensorflow:global_step/sec: 758.623\n",
      "INFO:tensorflow:loss = 0.024364924, step = 4101 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 1072.78\n",
      "INFO:tensorflow:loss = 0.024436777, step = 4201 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 1058.06\n",
      "INFO:tensorflow:loss = 0.022442587, step = 4301 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1064.89\n",
      "INFO:tensorflow:loss = 0.021464357, step = 4401 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1054.69\n",
      "INFO:tensorflow:loss = 0.020484405, step = 4501 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 979.756\n",
      "INFO:tensorflow:loss = 0.019571701, step = 4601 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 926.089\n",
      "INFO:tensorflow:loss = 0.018716846, step = 4701 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 1025.61\n",
      "INFO:tensorflow:loss = 0.017873505, step = 4801 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 1013.54\n",
      "INFO:tensorflow:loss = 0.017079195, step = 4901 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 990.25\n",
      "INFO:tensorflow:loss = 0.016311757, step = 5001 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 1067.31\n",
      "INFO:tensorflow:loss = 0.015575739, step = 5101 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1061.25\n",
      "INFO:tensorflow:loss = 0.014863347, step = 5201 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1054.72\n",
      "INFO:tensorflow:loss = 0.014184732, step = 5301 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1119.81\n",
      "INFO:tensorflow:loss = 0.013519479, step = 5401 (0.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 1132.1\n",
      "INFO:tensorflow:loss = 0.012887007, step = 5501 (0.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 1069.55\n",
      "INFO:tensorflow:loss = 0.012263631, step = 5601 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1092.15\n",
      "INFO:tensorflow:loss = 0.011675164, step = 5701 (0.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 1104.67\n",
      "INFO:tensorflow:loss = 0.011131456, step = 5801 (0.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 1130.97\n",
      "INFO:tensorflow:loss = 0.010514823, step = 5901 (0.088 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into ./output\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.010005514.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x0000017DC7BC57B8>, 'hidden_units': [10, 20, 10], 'feature_columns': (_RealValuedColumn(column_name='', dimension=4, default_value=None, dtype=tf.float32, normalizer=None),), 'optimizer': None, 'activation_fn': <function relu at 0x0000017DC114BE18>, 'dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]\n",
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                            hidden_units=[10, 20, 10],\n",
    "                                            n_classes=3,\n",
    "                                            model_dir=\"./output\")\n",
    " \n",
    "# Fit model.\n",
    "classifier.fit(X_train, y_train, steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./output\\model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-15-23:57:26\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./output\\model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-15-23:57:26\n",
      "INFO:tensorflow:Saving dict for global step 6000: accuracy = 0.95555556, global_step = 6000, loss = 0.15762234\n",
      "Accuracy: 0.955556\n"
     ]
    }
   ],
   "source": [
    "iris_predictions = list(classifier.predict(X_test))\n",
    "\n",
    "# Evaluate accuracy.\n",
    "accuracy_score = classifier.evaluate(X_test, y_test)[\"accuracy\"]\n",
    "print('Accuracy: {0:f}'.format(accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        14\n",
      "          1       0.93      0.93      0.93        15\n",
      "          2       0.94      0.94      0.94        16\n",
      "\n",
      "avg / total       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,iris_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
